---
permalink: /
author_profile: true
title: "About me"
excerpt: "About me"
redirect_from: 
  - /about/
  - /about.html
---
I am a 2nd year master student in Cognitive Science Program at [Seoul National University][1], advised by [Prof. Byoung-Tak Zhang][2]. My research interests mainly span in computer vision and natural language processing, and machine learning. I'm particularly interested in machine learning and its application in building agents that can see everyday scenes and fluently communicate with people. <br>
Prior to joining graduate school, I received my Bachelor's degree in software and computer science from [Ajou University][3]. 
<br>

## Recent News
<span style="color:#ff7272"><b>NEW!</b></span> [October 2019] <a href="https://arxiv.org/abs/1902.09368">Our EMNLP paper</a> has been accepted to ICCV 2019 <a href="https://videoturingtest.github.io">Video Turing Test workshop</a> as a spotlight talk.

<span style="color:#ff7272"><b>NEW!</b></span> [October 2019] I gave an invited talk at <a href="https://www.skt.ai">SK Telecom AI Center</a>.

<span style="color:#ff7272"><b>NEW!</b></span> [August 2019] Excited to announce that <a href="https://arxiv.org/abs/1902.09368">our paper</a> has been accepted to <a href="https://www.emnlp-ijcnlp2019.org/">EMNLP 2019</a>.
<details>
  <summary>show more</summary>

  <p><span style="color:#ff7272"><b>NEW!</b></span> [June 2019] Our proposed method ranks <b>3rd place</b> on <a href="https://visualdialog.org/challenge/2019">Visual Dialog Challenge 2019</a>!!</p> 
  
  <p><span style="color:#ff7272"><b>NEW!</b></span> [August 2018] We have a paper accepted to ECCV 2018 Workshop on <a href="http://vizwiz.org/workshop/">VizWiz Grand Challenge</a>.</p>  
</details>

## Publications
<table align="center" style="border-collapse: collapse; border: none;" >
    <!-- Dual Attention Networks -->
    <tr style="border: none;">
        <td align="center" style="border: none;"><img src="https://github.com/gicheonkang/gicheonkang.github.io/blob/master/images/DAN-19.png?raw=true" alt="Photo" width="300" height="150" /></td>
        <td style="border: none;"></td>
        <td align="left" style="border: none;"><b><span style="font-size: 17px;">Dual Attention Networks for Visual Reference Resolution in Visual Dialog</span></b><br>
          <span style="font-size:15px;"><u>G.-C. Kang</u>, J. Lim, and B.-T. Zhang</span><br>
          <span style="font-size:15px;"><i>EMNLP 2019</i></span><br>
          <span style="font-size:15px;"><a class="btn btn--info" href="https://arxiv.org/pdf/1902.09368.pdf"> Paper </a></span>
          <span style="font-size:15px;"><a class="btn btn--success" href="https://github.com/gicheonkang/DAN-VisDial"> Code </a></span>
          <span style="font-size:15px;"><a class="btn btn--primary" href="https://docs.google.com/viewer?url=https://raw.githubusercontent.com/gicheonkang/gicheonkang.github.io/master/files/DAN-19-slide.pdf"> Slide </a></span>
        </td>
    </tr>
    <!-- CBAN -->
    <tr style="border: none;">
        <td style="border: none;" colspan="3"><hr style="border: dashed 1px #8c8b8b;"></td>
    </tr>
    <!-- Contextualized Bilinear Attention Networks -->
    <tr style="border: none;">
        <td align="center" style="border: none;"><img src="https://github.com/gicheonkang/gicheonkang.github.io/blob/master/images/CBAN-18.png?raw=true" alt="Photo" width="300" height="150" /></td>
        <td style="border: none;"></td>
        <td align="left" style="border: none;"><b><span style="font-size: 17px;">Contextualized Bilinear Attention Networks</span></b><br>
          <span style="font-size:15px;"><u>G.-C. Kang</u>, S. Son, and B.-T. Zhang</span><br>
          <span style="font-size:15px;"><i>ECCV 2018 VizWiz Workshop</i></span><br>
          <span style="font-size:15px;"><a class="btn btn--info" href="https://bi.snu.ac.kr/Publications/Conferences/International/ECCV2018_Workshop_VizWiz_GCKang.pdf"> Paper </a></span>
          </td> 
    </tr>
</table>

## Talks
* "*Dual Attention Nets for Visual Reference Resolution in VisDial* ", SK Telecom AI Center, 2019.

## Side Projects
<script async defer src="https://buttons.github.io/buttons.js"></script>
<table align="center" style="border-collapse: collapse; border: none;" >
    <!-- Dual Attention Networks -->
    <tr style="border: none;">
        <td align="center" style="border: none;"><img src="https://github.com/gicheonkang/gicheonkang.github.io/blob/master/images/fast-face-android.png?raw=true" alt="Photo" width="300" /></td>
        <td style="border: none;"></td>
        <td style="border: none;"><b><span style="font-size: 17px; text-align: left;">Fast-Face Android  </span></b><a class="github-button" href="https://github.com/gicheonkang/fast-face-android" data-size="large" data-show-count="true" aria-label="Star gicheonkang/fast-face-android on GitHub" style="float:right;">Star</a><br>
          <span style="font-size:15px; text-align: left;">Fast Face is an android application which detects facial landmark. It detects 68 landmarks of human face chin to eyebrow in real-time. Also, it can detect people up to 3 if you guys show your frontal faces.</span><br>
          <span style="font-size:15px; text-align: left;"><a class="btn btn--success" href="https://github.com/gicheonkang/fast-face-android"> Code </a></span>
        </td>
    </tr>    
</table>

<style>
  @media screen and (max-width: 750px) {
  table thead {
    border: none;
    clip: rect(0 0 0 0);
    height: 1px;
    margin: -1px;
    overflow: hidden;
    padding: 0;
    position: absolute;
    width: 1px;
  }
  
  table tr {
    border-bottom: 3px solid #ddd;
    display: block;
  }
  
  table td {
    border-bottom: 1px solid #ddd;
    display: block;
    text-align: left;
  }
  
  table td::before {
    content: attr(data-label);
    float: left;
  }
}
</style>

---
[1]: http://en.snu.ac.kr
[2]: https://bi.snu.ac.kr/~btzhang/
[3]: http://www.ajou.ac.kr/en/


